# Benchmarks Directory

This directory contains performance benchmark results comparing CV and MediaPipe detection methods.

## Files

- `benchmark_results_YYYYMMDD_HHMMSS.json` - Benchmark results with timestamp
  - Contains FPS statistics, latency measurements, detection rates, and stability metrics
  - Generated by `tools/benchmark_comparison.py`

## Benchmark Metrics

Each benchmark file contains:

### Per-Detector Statistics
- **FPS**: Mean, median, min, max, standard deviation
- **Latency**: Detection time in milliseconds
- **Detection Rate**: Percentage of frames where hand was detected
- **Finger Stability**: Variance in finger count detection (lower = more stable)
- **Frame Count**: Total frames processed

### Comparison Data
- Relative performance differences (%)
- Speed comparison (which detector is faster)
- Stability comparison (which has less variance)

## Running Benchmarks

```bash
# With calibration (recommended)
python tools/benchmark_comparison.py

# Skip calibration (use existing config)
python tools/benchmark_comparison.py -s

# Options:
# 1. Full benchmark (60s per detector)
# 2. Quick test (20s per detector)
# 3. Custom duration
```

## Interpreting Results

- **Higher FPS** = Faster processing
- **Lower Latency** = More responsive
- **Higher Detection Rate** = More reliable hand detection
- **Lower Finger Stability** = Less jitter in finger counting
